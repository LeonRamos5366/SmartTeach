# An√°lisis y Dise√±o de Algoritmos: Competencias para la Ingenier√≠a de Sistemas Computacionales

## Introducci√≥n

El an√°lisis y dise√±o de algoritmos constituye uno de los pilares fundamentales de la formaci√≥n en sistemas computacionales, especialmente en el contexto de la prueba EGEL (Examen General para el Egreso de la Licenciatura). No se trata √∫nicamente de memorizar procedimientos o t√©cnicas de programaci√≥n, sino de desarrollar la capacidad de **resolver problemas complejos mediante el pensamiento l√≥gico y riguroso**. Este documento est√° dise√±ado para guiar a estudiantes y profesionales hacia el dominio de competencias que les permitan integrarse exitosamente al mercado internacional de las tecnolog√≠as de la informaci√≥n[1].

La relevancia de esta √°rea radica en que los egresados de licenciaturas en ingenier√≠a computacional deben ser capaces de analizar problemas reales, descomponer su complejidad, dise√±ar soluciones algor√≠tmicas eficientes y evaluar el desempe√±o de estas soluciones. El presente documento se estructura conforme a los niveles cognitivos establecidos por la taxonom√≠a de Bloom revisada (2001), garantizando que el estudiante no solo **comprenda** los conceptos b√°sicos, sino que progrese hacia la **aplicaci√≥n**, **an√°lisis**, **evaluaci√≥n** e incluso la **creaci√≥n** de nuevas soluciones algor√≠tmicas[2].

## 1. Fundamentos Conceptuales
## üéØ **Objetivo general**

Que el estudiante comprenda los principios del an√°lisis y dise√±o de algoritmos, sea capaz de aplicarlos en problemas computacionales reales, analice su eficiencia y eval√∫e diferentes alternativas para seleccionar la m√°s adecuada.

---

# **1. Introducci√≥n al An√°lisis y Dise√±o de Algoritmos (Comprender)**

##  **Resumen**

Un **algoritmo** es un conjunto ordenado y finito de pasos para resolver un problema.
El **an√°lisis de algoritmos** estudia el rendimiento (tiempo, espacio) de una soluci√≥n, mientras que el **dise√±o de algoritmos** se ocupa de crear algoritmos correctos, eficientes y √≥ptimos.

### Principales razones para analizar algoritmos:

* Determinar qu√© tan eficiente ser√° una soluci√≥n antes de implementarla.
* Comparar alternativas para un mismo problema.
* Estimar recursos computacionales necesarios.

### Conceptos clave:

* **Correcci√≥n:** el algoritmo resuelve el problema.
* **Eficiencia temporal:** tiempo de ejecuci√≥n.
* **Eficiencia espacial:** memoria utilizada.
* **Notaci√≥n Big-O:** modela el crecimiento del tiempo seg√∫n el tama√±o del input.

---

#  **2. Complejidad Algor√≠tmica (Comprender / Analizar)**

##  **Resumen**

La notaci√≥n Big-O describe el peor caso del costo de un algoritmo. Algunas complejidades comunes:

| Complejidad | Nombre      | Ejemplo t√≠pico                |
| ----------- | ----------- | ----------------------------- |
| O(1)        | Constante   | Acceso a arreglo              |
| O(log n)    | Logar√≠tmica | B√∫squeda binaria              |
| O(n)        | Lineal      | Recorrido secuencial          |
| O(n log n)  | Cuasilineal | Mergesort                     |
| O(n¬≤)       | Cuadr√°tica  | Burbujas                      |
| O(2‚Åø)       | Exponencial | Fuerza bruta con subconjuntos |
| O(n!)       | Factorial   | Permutaciones                 |

---

#  **3. T√©cnicas de Dise√±o de Algoritmos (Comprender / Aplicar)**

##  **Principales t√©cnicas:**

###  **1. Divide y vencer√°s**

Divide el problema en subproblemas m√°s peque√±os.
*Ejemplo:* Mergesort, Quicksort.

###  **2. Programaci√≥n din√°mica**

Resuelve subproblemas y guarda los resultados para evitar recalcularlos.
*Ejemplo:* Fibonacci optimizado, mochila 0/1.

###  **3. Algoritmos voraces**

Toma decisiones locales √≥ptimas esperando un √≥ptimo global.
*Ejemplo:* Kruskal, Huffman.

###  **4. Retroceso (Backtracking)**

Explora soluciones posibles deshaciendo decisiones err√≥neas.
*Ejemplo:* Laberintos, N-reinas.

###  **5. Fuerza bruta**

Explora todas las combinaciones posibles.
√ötil cuando el espacio de soluciones es peque√±o.

---

#  **4. Proceso para Dise√±ar un Algoritmo (Aplicar / Analizar)**

### 1. **Definir el problema** (inputs, outputs, restricciones).

### 2. **Elegir una t√©cnica de soluci√≥n** (divide y vencer√°s, voraz, etc.).

### 3. **Modelar el algoritmo**:

* Diagrama de flujo
* Pseudoc√≥digo
* An√°lisis paso a paso

### 4. **Analizar eficiencia temporal y espacial**.

### 5. **Validar casos de prueba**.

### 6. **Optimizar si es necesario**.

---

#  **5. Preguntas clave por nivel cognitivo**

##  **Comprender**

* ¬øQu√© es un algoritmo y por qu√© es importante analizarlo?
* ¬øQu√© representa la notaci√≥n Big-O?
* ¬øCu√°l es la diferencia entre mejor caso, peor caso y caso promedio?

##  **Aplicar**

* Determina la complejidad temporal de un algoritmo dado.
* Escribe un algoritmo que calcule el m√°ximo en un arreglo usando pseudoc√≥digo.
* Aplica divide y vencer√°s para resolver un problema simple.

##  **Analizar**

* Compara dos algoritmos que solucionan el mismo problema e identifica cu√°l es m√°s eficiente.
* Dado un pseudoc√≥digo, identifica qu√© partes impactan en la complejidad.
* ¬øQu√© pasar√≠a si cambiamos la estructura de datos?

##  **Evaluar**

* ¬øEs mejor usar un algoritmo voraz o programaci√≥n din√°mica en un caso espec√≠fico?
* Eval√∫a si vale la pena optimizar un algoritmo que ya es O(n log n).
* Selecciona la mejor t√©cnica para un problema de b√∫squeda en grafos.

---

#  **6. Ejercicios pr√°cticos**

##  **Nivel: Comprender**

1. Explica en tus propias palabras qu√© es la complejidad temporal.
2. Clasifica estos algoritmos en su complejidad:

   * B√∫squeda secuencial
   * B√∫squeda binaria
   * Doble ciclo anidado

---

## **Nivel: Aplicar**

3. Escribe el pseudoc√≥digo de un algoritmo que cuente cu√°ntos n√∫meros pares hay en una lista.
4. Calcula la complejidad del siguiente pseudoc√≥digo:

```
for i = 1 to n:
    print(i)
for j = 1 to n:
    for k = 1 to n:
        print(j, k)
```

---

##  **Nivel: Analizar**

5. Compara la complejidad de Mergesort y Quicksort en el peor caso.
6. Analiza qu√© pasar√≠a si usaras fuerza bruta para encontrar un valor en un arreglo ordenado.

---

##  **Nivel: Evaluar**

7. Eval√∫a si conviene usar backtracking o un algoritmo voraz para el problema de encontrar una ruta √≥ptima en un laberinto.
8. Determina si un algoritmo O(n¬≤) es adecuado cuando n = 1,000,000. Justifica.

---

#  **7. Mini proyecto integrador**

Desarrolla un algoritmo para resolver el siguiente problema:

###  **Problema:**

Dado un arreglo desordenado de n√∫meros enteros, encontrar los **k elementos m√°s grandes**.

###  Requisitos:

* Dise√±a dos soluciones (por ejemplo, ordenamiento + selecci√≥n, o heap).
* Calcula su complejidad.
* Programa ambas (en pseudoc√≥digo o lenguaje de tu elecci√≥n).
* Eval√∫a cu√°l es mejor seg√∫n diferentes valores de *n* y *k*.

*Niveles cognitivos alcanzados: Aplicar, Analizar, Evaluar.*

## Ejemplos 
Perfecto ‚Äî aqu√≠ tienes **los ejercicios resueltos** (con explicaciones paso a paso, complejidad y c√≥digo de ejemplo en Python donde aplica). Los ejercicios est√°n organizados por nivel cognitivo tal como en la gu√≠a anterior.

---

# üü¶ Nivel: Comprender ‚Äî Resueltos

**1.** Explica en tus propias palabras qu√© es la complejidad temporal.
**Respuesta:** La complejidad temporal es una forma de medir c√≥mo crece el tiempo de ejecuci√≥n de un algoritmo cuando aumenta el tama√±o de la entrada (n). Se expresa con notaciones asint√≥ticas (por ejemplo (O(n)), (O(n^2))) que describen la tasa de crecimiento dominante, ignorando constantes y t√©rminos de menor orden.

**2.** Clasifica estos algoritmos en su complejidad:

* B√∫squeda secuencial ‚Üí **O(n)** (recorre elementos hasta encontrar el objetivo).
* B√∫squeda binaria ‚Üí **O(log n)** (requiere arreglo ordenado y divide el espacio por 2 cada paso).
* Doble ciclo anidado ‚Üí **O(n¬≤)** (dos bucles que dependen de n generan n √ó n operaciones).

---

# üü© Nivel: Aplicar ‚Äî Resueltos

**3.** Pseudoc√≥digo + Python: algoritmo que cuenta cu√°ntos n√∫meros pares hay en una lista.

Pseudoc√≥digo:

```
func contar_pares(lista):
    contador = 0
    para cada x en lista:
        si x % 2 == 0:
            contador = contador + 1
    retornar contador
```

C√≥digo Python:

```python
def contar_pares(lista):
    contador = 0
    for x in lista:
        if x % 2 == 0:
            contador += 1
    return contador

# Ejemplo
arr = [3,4,7,8,10]
print(contar_pares(arr))  # salida: 3
```

**Complejidad temporal:** (O(n)). **Espacio:** (O(1)) adicional.

---

**4.** Calcula la complejidad del pseudoc√≥digo:

```
for i = 1 to n:
    print(i)
for j = 1 to n:
    for k = 1 to n:
        print(j, k)
```

An√°lisis: primer bucle ‚Üí (O(n)). Segundo ‚Üí doble anidado (O(n^2)). Total dominado por (O(n^2)).
**Respuesta:** (O(n^2)).

---

# üüß Nivel: Analizar ‚Äî Resueltos

**5.** Compara la complejidad de Mergesort y Quicksort en el peor caso.

* **Mergesort:** siempre (O(n \log n)) en mejor, promedio y peor caso. Necesita espacio adicional (O(n)) (si se implementa no in-place).
* **Quicksort:** promedio (O(n \log n)), peor caso (O(n^2)) (cuando el pivote es siempre el peor, p. ej. lista ya ordenada y pivote mal elegido).
  **Conclusi√≥n:** en el peor caso Mergesort es mejor ((O(n\log n)) vs (O(n^2))). Por eso, en entornos donde el peor caso es cr√≠tico, Mergesort es preferido; Quicksort suele preferirse por rendimiento pr√°ctico (constantes m√°s peque√±as) y uso de memoria cuando se elige buen pivote (randomizado o mediana).

---

**6.** ¬øQu√© pasar√≠a si usaras fuerza bruta para encontrar un valor en un arreglo ordenado?

* Fuerza bruta (recorrido secuencial) cuesta (O(n)).
* Si el arreglo est√° ordenado, usar **b√∫squeda binaria** cuesta (O(\log n)) ‚Äî mucho m√°s eficiente para grandes (n).
  **Conclusi√≥n:** Usar fuerza bruta en arreglo ordenado es sub√≥ptimo; conviene aprovechar el orden y usar b√∫squeda binaria.

---

# üü• Nivel: Evaluar ‚Äî Resueltos

**7.** ¬øBacktracking o voraz para encontrar una ruta √≥ptima en un laberinto?

* **Voraz:** tomar la decisi√≥n que parece mejor localmente puede no encontrar la ruta global √≥ptima (p. ej. quedarse bloqueado en callej√≥n).
* **Backtracking (DFS con retroceso) o algoritmos de b√∫squeda (BFS, Dijkstra, A*)**: garantizan encontrar soluci√≥n (BFS encuentra la ruta m√°s corta por n√∫mero de pasos en grafos no ponderados; Dijkstra/A* para grafos ponderados/heur√≠sticos).
  **Evaluaci√≥n:** Para garantizar optimalidad en longitud de camino en un laberinto no ponderado ‚Üí **BFS** (mejor elecci√≥n). Si se tienen pesos o heur√≠stica ‚Üí **Dijkstra** o **A***. Backtracking puede encontrar soluciones pero no garantiza √≥ptimo y puede ser costoso; voraz no garantiza soluci√≥n √≥ptima.

---

**8.** ¬øEs adecuado un algoritmo (O(n^2)) cuando (n = 1{,}000{,}000)? Justifica.

* (n^2 = 10^{12}) operaciones ‚Äî impracticable en casi todos los entornos (tomar√≠a horas o d√≠as seg√∫n la m√°quina).
* Para (n) grande (millones), se prefieren algoritmos (O(n \log n)) o (O(n)).
  **Conclusi√≥n:** No adecuado. Si datos son peque√±os (p. ej. n ‚â§ 10^4) un (O(n^2)) puede ser aceptable; para (n=10^6) es inviable.

Estimaci√≥n r√°pida: si CPU hace (10^9) operaciones/s te√≥ricas (ideal), (10^{12}) ops ‚âà 1000 segundos = ~17 minutos ‚Äî pero en realidad overhead/constantes har√°n m√°s tiempo. En pr√°ctica es inaceptable.

---

# üî∑ Mini proyecto integrador ‚Äî Soluciones propuestas + c√≥digo de ejemplo

**Problema:** Dado un arreglo desordenado de enteros, encontrar los **k** elementos m√°s grandes.

Te doy **dos soluciones** (ordenamiento + selecci√≥n y heap), m√°s una menci√≥n de Quickselect.

---

## Soluci√≥n A ‚Äî Ordenar y seleccionar

* Idea: ordenar el arreglo de mayor a menor y tomar los primeros k.
* **Complejidad:** ordenar (O(n \log n)) + seleccionar (O(k)) ‚Üí **O(n log n)**.
* **C√≥digo Python:**

```python
def k_mayores_orden(arreglo, k):
    arreglo_sorted = sorted(arreglo, reverse=True)
    return arreglo_sorted[:k]

# Ejemplo
arr = [5,1,9,3,7,2,8]
print(k_mayores_orden(arr, 3))  # salida: [9,8,7]
```

* **Ventaja:** simple, estable y f√°cil.
* **Desventaja:** innecesaria sobrecarga si k << n.

---

## Soluci√≥n B ‚Äî Min-heap de tama√±o k (eficiente cuando k << n)

* Idea: mantener un heap m√≠nimo con los k mayores vistos hasta ahora.

  * Recorres el arreglo: insertas en heap hasta k elementos; luego para cada nuevo elemento x:

    * si x > heap.min ‚Üí pop min y push x.
* **Complejidad:** cada push/pop es (O(\log k)). Recorres n elementos ‚Üí **O(n log k)**.
* **Espacio:** (O(k)).
* **C√≥digo Python:**

```python
import heapq

def k_mayores_heap(arreglo, k):
    if k <= 0:
        return []
    heap = []
    for x in arreglo:
        if len(heap) < k:
            heapq.heappush(heap, x)
        else:
            if x > heap[0]:
                heapq.heapreplace(heap, x)  # pop+push m√°s eficiente
    # heap contiene los k mayores en orden no descendente
    return sorted(heap, reverse=True)

# Ejemplo
arr = [5,1,9,3,7,2,8]
print(k_mayores_heap(arr, 3))  # salida: [9,8,7]
```

* **Ventaja:** muy eficiente cuando (k \ll n).
* **Desventaja:** implementa overhead de heap; si k ‚âà n, se acerca a O(n log n).

---

## Soluci√≥n C ‚Äî Quickselect (promedio O(n))

* **Idea:** algoritmo de selecci√≥n basado en particiones (como Quicksort). Encuentra la k-√©sima mayor en tiempo promedio (O(n)), luego toma todos mayores/iguales.
* **Complejidad promedio:** (O(n)). Peor caso (O(n^2)) (soluci√≥n: usar selecci√≥n mediana de medianas para garantizar (O(n)) peor caso).
* **Cuando usar:** cuando quieres el k-√©simo elemento r√°pidamente sin ordenar todo.

---

## Comparaci√≥n pr√°ctica

* Si (k) peque√±o comparado con (n): **Min-heap O(n log k)** es la mejor pr√°ctica.
* Si (k) cercano a (n): ordenar y tomar es pr√°ctico (**O(n log n)**).
* Si buscas rendimiento promedio √≥ptimo y quieres evitar almacenar muchos elementos: **Quickselect**.

---

# ‚úÖ Ejemplo completo: an√°lisis con n y k

Supongamos (n = 10^7) y (k = 10^3):

* Ordenar: (O(n \log n)) ‚âà (10^7 \times \log_2(10^7) ‚âà 10^7 \times 23 ‚âà 2.3 \times 10^8) comparaciones.
* Heap: (O(n \log k)) ‚âà (10^7 \times \log_2(10^3) ‚âà 10^7 \times 10 ‚âà 10^8) operaciones ‚Äî aproximadamente 2.3√ó m√°s eficiente que ordenar en este ejemplo.
* Quickselect: (\approx O(n)) promedio ‚Üí (~10^7) operaciones de partici√≥n (con costos constantes mayores), potencialmente mejor.

---

# üìé Ejercicios resueltos adicionales (para practicar)

**Ejercicio:** Dado el arreglo `[2,5,1,9,4,8,3,7,6]`, k=4:

* Orden + seleccionar ‚Üí `[9,8,7,6]`.
* Heap ‚Üí `[9,8,7,6]`.
* Quickselect ‚Üí encuentra 4¬∫ mayor = 6, luego se recogen ‚â• 6 ‚Üí los 4.

**Ejercicio (complejidad):** Determina la complejidad del siguiente fragmento:

```
for i in range(n):
    for j in range(i, n):
        do_constant_work()
```

An√°lisis: n√∫mero total de iteraciones = sum_{i=0}^{n-1} (n-i) = n + (n-1) + ... + 1 = n(n+1)/2 ‚Üí (O(n^2)).

